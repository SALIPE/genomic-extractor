{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules and Model File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "    using Pkg\n",
    "    Pkg.activate(\".\")\n",
    "    Pkg.resolve()\n",
    "    Pkg.add(\"Flux\")\n",
    "    Pkg.instantiate()\n",
    "\n",
    "end\n",
    "\n",
    "include(\"modules/DataIO.jl\")\n",
    "include(\"modules/Classification.jl\")\n",
    "include(\"modules/Model.jl\")\n",
    "\n",
    "using FLoops,\n",
    "    FASTX,\n",
    "    LinearAlgebra,\n",
    "    Normalization,\n",
    "    Statistics,\n",
    "    Plots,Flux\n",
    "\n",
    "using\n",
    "    .DataIO,\n",
    "    .Model,\n",
    "    .Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta::String = \"/home/salipe/Desktop/datasets/test_voc/test/Alpha.fasta\"\n",
    "modelCachedFile::String = \"$(pwd())/.project_cache/trained_model.dat\" \n",
    "\n",
    "sequences = Vector{Tuple{String,Base.CodeUnits}}()\n",
    "for record in open(FASTAReader, fasta)\n",
    "    seq::String = sequence(String, record)\n",
    "    id::String = identifier(record)\n",
    "    push!(sequences, (replace(id, r\"\\/|\\|\" => \"_\"), codeunits(seq)))\n",
    "    break\n",
    "end\n",
    "\n",
    "model::Union{Nothing,Dict{String,Tuple{BitArray,Vector{Vector{Float64}},Vector{String}}}} = DataIO.load_cache(modelCachedFile)\n",
    "@show model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesing model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalHist::Union{Nothing,Vector{UInt16}} = nothing\n",
    "finalMask::BitArray = trues(maximum(x -> length(x[2][1]), model))\n",
    "\n",
    "plt = plot(title=\"Points\")\n",
    "\n",
    "for (key, (marked, _, kmers)) in model\n",
    "\n",
    "    cache_path = \"$(pwd())/.project_cache/$(key)_outmask.dat\"\n",
    "    cache::Union{Nothing,Tuple{String,Tuple{Vector{UInt16},BitArray},Vector{String}}} = DataIO.load_cache(cache_path)\n",
    "    # plot!(marked)\n",
    "\n",
    "    finalMask[1:length(marked)] = finalMask[1:length(marked)] .* marked\n",
    "    if isnothing(finalHist)\n",
    "        finalHist = cache[2][1]\n",
    "    else\n",
    "        current_hist = cache[2][1]\n",
    "        max_len = max(length(finalHist), length(current_hist))\n",
    "\n",
    "        # Create padded versions\n",
    "        padded_final = [finalHist; ones(UInt16, max_len - length(finalHist))]\n",
    "        padded_current = [current_hist; ones(UInt16, max_len - length(current_hist))]\n",
    "\n",
    "        # Element-wise multiplication\n",
    "        finalHist = padded_final .* padded_current\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "start = 0\n",
    "current = false\n",
    "\n",
    "\n",
    "# plot!(finalMask)\n",
    "# plot(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = Vector{UnitRange{Int64}}()\n",
    "for (i, bit) in enumerate(finalMask)\n",
    "    if bit && !current\n",
    "        start = i\n",
    "        current = true\n",
    "    elseif !bit && current\n",
    "        current = false\n",
    "        push!(teste,(start:i-1))\n",
    "    end\n",
    "end\n",
    "if current\n",
    "    push!(teste,(start:length(finalMask)))\n",
    "end\n",
    "\n",
    "@show teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = Vector{Tuple{String,Vector{Int16}}}()\n",
    "(id, inputSequence) = sequences[1]\n",
    "\n",
    "for (key, (marked, _, kmers)) in model\n",
    "    probs = Vector{Integer}()\n",
    "    inputlen = minimum(length, [inputSequence, marked])\n",
    "    limitedMark::BitArray = marked[1:inputlen]\n",
    "    start = 0\n",
    "    current = false\n",
    "\n",
    "    for (i, bit) in enumerate(limitedMark)\n",
    "        if bit && !current\n",
    "            start = i\n",
    "            current = true\n",
    "        elseif !bit && current\n",
    "            current = false\n",
    "            count = @views Classification.countPatterns(inputSequence[start:i-1], kmers)\n",
    "\n",
    "            push!(probs, convert(Int16, count))\n",
    "        end\n",
    "    end\n",
    "    if current\n",
    "        if (length([start:inputlen]) < length(kmers[1]))\n",
    "            start = start - length(kmers[1])\n",
    "        end\n",
    "\n",
    "        count = @views Classification.countPatterns(inputSequence[start:inputlen], kmers)\n",
    "        push!(probs, convert(Int16, count))\n",
    "\n",
    "\n",
    "    end\n",
    "\n",
    "    push!(chart, (key, probs))\n",
    "end\n",
    "\n",
    "\n",
    "@show chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.081078681494729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "max_len = maximum(x->length(x[2]), chart)\n",
    "x = [reshape([var[2];zeros(Int16, max_len - length(var[2]))],  (1,max_len)) for var in chart]\n",
    "\n",
    "N, L, C = 1, max_len, 5  # Batch size 1, sequence length 35, 5 classes\n",
    "logits = Array{Int16}(undef,1,max_len, 5)\n",
    "\n",
    "for i in 1:length(x)\n",
    "    logits[:,:,i] = x[i]\n",
    "end\n",
    "\n",
    "\n",
    "y_indices = rand(1:C, N, L)  # Class indices for each position\n",
    "\n",
    "# Convert to one-hot (optional)\n",
    "y_true = Flux.onehotbatch(vec(y_indices), 1:C)  # Shape (C, N*L)\n",
    "y_true = reshape(y_true, C, N, L)  # Reshape to (N, L, C)\n",
    "y_true = permutedims(y_true, (2, 3, 1))  # Final shape (N, L, C)\n",
    "\n",
    "# Compute loss\n",
    "log_probs = Flux.logsoftmax(logits; dims=3)\n",
    "loss = -mean(y_true .* log_probs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×35×5 Array{Bool, 3}:\n",
       "[:, :, 1] =\n",
       " 1  0  0  1  0  1  0  0  0  0  0  0  1  …  0  1  0  0  1  0  0  0  0  0  0  0\n",
       "\n",
       "[:, :, 2] =\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0  …  1  0  1  1  0  1  0  0  0  0  0  0\n",
       "\n",
       "[:, :, 3] =\n",
       " 0  1  0  0  0  0  1  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  1  0  0\n",
       "\n",
       "[:, :, 4] =\n",
       " 0  0  1  0  0  0  0  0  1  1  1  0  0  …  0  0  0  0  0  0  0  0  1  0  1  1\n",
       "\n",
       "[:, :, 5] =\n",
       " 0  0  0  0  0  0  0  1  0  0  0  1  0  …  0  0  0  0  0  0  1  1  0  0  0  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@show y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
